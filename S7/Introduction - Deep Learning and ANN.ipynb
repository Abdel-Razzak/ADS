{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "24ca50a0-b9ad-425d-a28f-6bd3ca3ac378"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "3896ecb2-47fa-4dbc-a2ff-9c76e9dfe93e"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Deep learning allows computational models that are composed of multiple processing **layers** to learn representations of data with multiple levels of abstraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "8c3060aa-fee9-438c-bc60-4685c0eb4750"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "6287766f-972f-4b4d-bee7-5418f0af74de"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Deep learning** is one of the leading tools in data analysis these days and one of the most common frameworks for deep learning is **Keras**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "2f1c6299-954a-461a-b5c1-a86a1d12ad15"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Tutorial will provide an introduction to deep learning using `keras` with practical code examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Section will cover:\n",
    "\n",
    "* Getting a conceptual understanding of multi-layer neural networks\n",
    "* Training neural networks for image classification\n",
    "* Implementing the powerful backpropagation algorithm\n",
    "* Debugging neural network implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "5e13607b-3ec5-4a95-a2d8-f898f20748da"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building Blocks: Artificial Neural Networks (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "4fa2e86a-be32-4e78-96d9-f511a07e3908"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In machine learning and cognitive science, an artificial neural network (ANN) is a network inspired by biological neural networks which are used to estimate or approximate functions that can depend on a large number of inputs that are generally unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "df0121bc-10f1-4ace-840e-6fc89c6fdc7f"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An ANN is built from nodes (neurons) stacked in layers between the feature vector and the target vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "c25d7194-10bd-4196-9d4c-592bf6e188f9"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A node in a neural network is built from Weights and Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "15260f90-13d1-4fcc-afc6-379c507cb950"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An early version of ANN built from one node was called the **Perceptron**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "92d4603e-7e39-4156-818c-785df6189fe8"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"imgs/Perceptron.png\" width=\"45%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "356d5ec7-3392-4daa-9671-4cc7111c5c91"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Perceptron is an algorithm for supervised learning of binary classifiers. functions that can decide whether an input (represented by a vector of numbers) belongs to one class or another.\n",
    "\n",
    "Much like logistic regression, the weights in a neural net are being multiplied by the input vertor summed up and feeded into the activation function's input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Perceptron Network can be designed to have *multiple layers*, leading to the **Multi-Layer Perceptron** (aka `MLP`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"imgs/MLP.png\" width=\"45%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Single Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"imgs/single_layer.png\" width=\"65%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Update Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We use a **gradient descent** optimization algorithm to learn the _Weights Coefficients_ of the model.\n",
    "<br><br>\n",
    "- In every **epoch** (pass over the training set), we update the weight vector $w$ using the following update rule:\n",
    "\n",
    "$$\n",
    "w = w + \\Delta w, \\text{where } \\Delta w = - \\eta \\nabla J(w)\n",
    "$$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "In other words, we computed the gradient based on the whole training set and updated the weights of the model by taking a step into the **opposite direction** of the gradient $ \\nabla J(w)$. \n",
    "\n",
    "In order to fin the **optimal weights of the model**, we optimized an objective function (e.g. the Sum of Squared Errors (SSE)) cost function $J(w)$. \n",
    "\n",
    "Furthermore, we multiply the gradient by a factor, the learning rate $\\eta$ , which we choose carefully to balance the **speed of learning** against the risk of overshooting the global minimum of the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In **gradient descent optimization**, we update all the **weights simultaneously** after each epoch, and we define the _partial derivative_ for each weight $w_j$ in the weight vector $w$ as follows:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w_j} J(w) = \\sum_{i} ( y^{(i)} - a^{(i)} )  x^{(i)}_j\n",
    "$$\n",
    "\n",
    "**Note**: _The superscript $(i)$ refers to the ith sample. The subscript $j$ refers to the jth dimension/feature_\n",
    "\n",
    "\n",
    "Here $y^{(i)}$ is the target class label of a particular sample $x^{(i)}$ , and $a^{(i)}$ is the **activation** of the neuron \n",
    "\n",
    "(which is a linear function in the special case of _Perceptron_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the **activation function** $\\phi(\\cdot)$ as follows:\n",
    "\n",
    "$$\n",
    "\\phi(z) = z = a = \\sum_{j} w_j x_j = \\mathbf{w}^T \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we used the **activation** $\\phi(z)$ to compute the gradient update, we may use a **threshold function** _(Heaviside function)_ to squash the continuous-valued output into binary class labels for prediction:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\begin{cases}\n",
    "    1 & \\text{if } \\phi(z) \\geq 0 \\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building Neural Nets from scratch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Idea:\n",
    "\n",
    "We will build the neural networks from first principles. \n",
    "We will create a very simple model and understand how it works. We will also be implementing backpropagation algorithm. \n",
    "\n",
    "**Please note that this code is not optimized and not to be used in production**. \n",
    "\n",
    "This is for instructive purpose - for us to understand how ANN works. \n",
    "\n",
    "Libraries like `theano` have highly optimized code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron and Adaline Models\n",
    "\n",
    "Take a look at this notebook : <a href=\"extra/1.1.1 Perceptron and Adaline.ipynb\" target=\"_blank_\"> Perceptron and Adaline </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a sneak peek of alternate (production ready) implementation of _Perceptron_ for instance try:\n",
    "```python\n",
    "from sklearn.linear_model import Perceptron\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the multi-layer neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/multi-layers-1.png\" width=\"50%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see how to connect **multiple single neurons** to a **multi-layer feedforward neural network**; this special type of network is also called a **multi-layer perceptron** (MLP). \n",
    "\n",
    "The figure shows the concept of an **MLP** consisting of three layers: one _input_ layer, one _hidden_ layer, and one _output_ layer. \n",
    "\n",
    "The units in the hidden layer are fully connected to the input layer, and the output layer is fully connected to the hidden layer, respectively. \n",
    "\n",
    "If such a network has **more than one hidden layer**, we also call it a **deep artificial neural network**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we denote the `ith` activation unit in the `lth` layer as $a_i^{(l)}$ , and the activation units $a_0^{(1)}$ and \n",
    "$a_0^{(2)}$ are the **bias units**, respectively, which we set equal to $1$. \n",
    "<br><br>\n",
    "The _activation_ of the units in the **input layer** is just its input plus the bias unit:\n",
    "\n",
    "$$\n",
    "\\mathbf{a}^{(1)} = [a_0^{(1)}, a_1^{(1)}, \\ldots, a_m^{(1)}]^T = [1, x_1^{(i)}, \\ldots, x_m^{(i)}]^T\n",
    "$$\n",
    "<br><br>\n",
    "**Note**: $x_j^{(i)}$ refers to the jth feature/dimension of the ith sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on Notation (usually) Adopted\n",
    "\n",
    "The terminology around the indices (subscripts and superscripts) may look a little bit confusing at first. \n",
    "<br><br>\n",
    "\n",
    "You may wonder why we wrote $w_{j,k}^{(l)}$ and not $w_{k,j}^{(l)}$ to refer to \n",
    "the **weight coefficient** that connects the *kth* unit in layer $l$ to the jth unit in layer $l+1$. \n",
    "<br><br>\n",
    "\n",
    "What may seem a little bit quirky at first will make much more sense later when we **vectorize** the neural network representation. \n",
    "<br><br>\n",
    "\n",
    "For example, we will summarize the weights that connect the input and hidden layer by a matrix \n",
    "$$ W^{(1)} \\in \\mathbb{R}^{h×[m+1]}$$\n",
    "\n",
    "where $h$ is the number of hidden units and $m + 1$ is the number of hidden units plus bias unit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/multi-layers-2.png\" width=\"50%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Starting at the input layer, we forward propagate the patterns of the training data through the network to generate an output.\n",
    "\n",
    "* Based on the network's output, we calculate the error that we want to minimize using a cost function that we will describe later.\n",
    "\n",
    "* We backpropagate the error, find its derivative with respect to each weight in the network, and update the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/logistic_function.png\" width=\"50%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/fwd_step.png\" width=\"50%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/fwd_step_net.png\" width=\"50%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "5678486b-caf4-440b-be62-2f1286982c71"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The weights of each neuron are learned by **gradient descent**, where each neuron's error is derived with respect to it's weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/bkwd_step_net.png\" width=\"50%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Optimization is done for each layer with respect to the previous layer in a technique known as **BackPropagation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"imgs/backprop.png\" width=\"50%\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "5445cab1-b2b9-4492-a3be-c4063bd67610": {
     "id": "5445cab1-b2b9-4492-a3be-c4063bd67610",
     "prev": "ef2af7e1-6294-42cf-a434-b1e17cf679a7",
     "regions": {
      "4baa3e75-a346-47d1-a015-c9040545adbd": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "8c3060aa-fee9-438c-bc60-4685c0eb4750",
        "part": "whole"
       },
       "id": "4baa3e75-a346-47d1-a015-c9040545adbd"
      },
      "bde8ff6d-7eb8-4d83-b6ba-f57b94dc889d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3896ecb2-47fa-4dbc-a2ff-9c76e9dfe93e",
        "part": "whole"
       },
       "id": "bde8ff6d-7eb8-4d83-b6ba-f57b94dc889d"
      }
     }
    },
    "d263b7c7-85dc-422a-aec7-fa2c09bc1d23": {
     "id": "d263b7c7-85dc-422a-aec7-fa2c09bc1d23",
     "prev": "ff705989-f5c1-46a1-8f7a-0fe14a949357",
     "regions": {
      "053c599b-2e88-4270-bc7b-1299a2a2bd20": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4fa2e86a-be32-4e78-96d9-f511a07e3908",
        "part": "whole"
       },
       "id": "053c599b-2e88-4270-bc7b-1299a2a2bd20"
      }
     }
    },
    "e3153a08-42da-4785-a596-7a9ebb6a6f19": {
     "id": "e3153a08-42da-4785-a596-7a9ebb6a6f19",
     "prev": "5445cab1-b2b9-4492-a3be-c4063bd67610",
     "regions": {
      "215ebdb3-236e-4a0d-aa65-6b4fb839e5b3": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "2f1c6299-954a-461a-b5c1-a86a1d12ad15",
        "part": "whole"
       },
       "id": "215ebdb3-236e-4a0d-aa65-6b4fb839e5b3"
      },
      "6b33306d-283d-47ef-afec-1f8b5e7fa9a5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6287766f-972f-4b4d-bee7-5418f0af74de",
        "part": "whole"
       },
       "id": "6b33306d-283d-47ef-afec-1f8b5e7fa9a5"
      }
     }
    },
    "edcbed78-ec6f-4c1d-84f0-fb1601a07f1d": {
     "id": "edcbed78-ec6f-4c1d-84f0-fb1601a07f1d",
     "prev": "f912a9b4-1188-440a-b13e-86224d1dada5",
     "regions": {
      "b619970a-3b72-4add-88af-158f75e81f2f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "356d5ec7-3392-4daa-9671-4cc7111c5c91",
        "part": "whole"
       },
       "id": "b619970a-3b72-4add-88af-158f75e81f2f"
      },
      "d86b2236-e08b-44cf-9298-0c818a1c9c88": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "5678486b-caf4-440b-be62-2f1286982c71",
        "part": "whole"
       },
       "id": "d86b2236-e08b-44cf-9298-0c818a1c9c88"
      }
     }
    },
    "ef2af7e1-6294-42cf-a434-b1e17cf679a7": {
     "id": "ef2af7e1-6294-42cf-a434-b1e17cf679a7",
     "prev": "f59d310a-ea9f-4360-8151-6ea1c66a66ac",
     "regions": {
      "e33b4032-a118-4ab7-920b-5cd4c1bb0523": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "24ca50a0-b9ad-425d-a28f-6bd3ca3ac378",
        "part": "whole"
       },
       "id": "e33b4032-a118-4ab7-920b-5cd4c1bb0523"
      }
     }
    },
    "f59d310a-ea9f-4360-8151-6ea1c66a66ac": {
     "id": "f59d310a-ea9f-4360-8151-6ea1c66a66ac",
     "prev": null,
     "regions": {}
    },
    "f607e60a-8fc2-4061-bbbe-fb75f498cec7": {
     "id": "f607e60a-8fc2-4061-bbbe-fb75f498cec7",
     "prev": "d263b7c7-85dc-422a-aec7-fa2c09bc1d23",
     "regions": {
      "cea17e10-48c1-4b1a-a39e-5462b17adc89": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df0121bc-10f1-4ace-840e-6fc89c6fdc7f",
        "part": "whole"
       },
       "id": "cea17e10-48c1-4b1a-a39e-5462b17adc89"
      },
      "fe327edc-53cc-4a66-b242-ffbc1148099f": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "c25d7194-10bd-4196-9d4c-592bf6e188f9",
        "part": "whole"
       },
       "id": "fe327edc-53cc-4a66-b242-ffbc1148099f"
      }
     }
    },
    "f912a9b4-1188-440a-b13e-86224d1dada5": {
     "id": "f912a9b4-1188-440a-b13e-86224d1dada5",
     "prev": "f607e60a-8fc2-4061-bbbe-fb75f498cec7",
     "regions": {
      "213f5824-f494-4cf6-8458-5dd5d629794c": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "92d4603e-7e39-4156-818c-785df6189fe8",
        "part": "whole"
       },
       "id": "213f5824-f494-4cf6-8458-5dd5d629794c"
      },
      "b141fdfe-4270-4293-a445-2b5642daf56e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "15260f90-13d1-4fcc-afc6-379c507cb950",
        "part": "whole"
       },
       "id": "b141fdfe-4270-4293-a445-2b5642daf56e"
      }
     }
    },
    "ff705989-f5c1-46a1-8f7a-0fe14a949357": {
     "id": "ff705989-f5c1-46a1-8f7a-0fe14a949357",
     "prev": "e3153a08-42da-4785-a596-7a9ebb6a6f19",
     "regions": {
      "fe64f274-127a-4ab1-9a01-d011d67aa8fb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5e13607b-3ec5-4a95-a2d8-f898f20748da",
        "part": "whole"
       },
       "id": "fe64f274-127a-4ab1-9a01-d011d67aa8fb"
      }
     }
    }
   },
   "themes": {
    "default": "cdfd905a-2df0-447c-8f49-becf28e8e1b1",
    "theme": {
     "cdfd905a-2df0-447c-8f49-becf28e8e1b1": {
      "id": "cdfd905a-2df0-447c-8f49-becf28e8e1b1",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
